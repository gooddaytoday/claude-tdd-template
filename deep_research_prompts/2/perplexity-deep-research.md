Оптимизация вашего harness в первую очередь упирается в три вещи: внешнее подтверждение каждого RED/GREEN/REFACTOR перехода, явную спецификацию intent тестов и телеметрию по FixRequest‑циклам. На текущей архитектуре (6 агентов + Task Master + Phase Packets + Guard) это можно сделать без радикальных переделок — за счёт нескольких дополнительных артефактов, хук‑проверок и метрик.

***

## TDD как формальный автомат состояний

С точки зрения harness’а полезно явно считать весь цикл RED→GREEN→REFACTOR→CODE REVIEW→ARCHITECTURE→DOCUMENTATION конечным автоматом, где *единственный источник истины о состоянии* — Phase Packet + фактический результат тестового раннера, а не текстовый self‑report агента.[^1][^2]
Практика Anthropic для long‑running кодовых агентов — фиксировать прогресс через строго структурированные артефакты (feature‑list JSON, прогресс‑лог, git‑состояние), а не через «модель считает, что всё хорошо», и это напрямую транслируется в ваш TDD‑автомат.[^3][^1]

Рекомендуется добавить в skill.md явную state‑машину с допустимыми переходами (включая петли fix‑routing) и жёстким правилом: *любой статус `failed|needs-fix` в Phase Packet блокирует переход вперёд* до успешной переоценки. Это хорошо ложится на уже существующие `Status`/`AgentTaskStatus` поля и упрощает reasoning в Task Master.

***

## Ритуалы и guardrails против обхода RED/GREEN

Практика Anthropic для предотвращения «обхода» проверок — выносить критические проверки из головы агента в независимый quality gate, который переисполняет ключевые команды и проверяет инварианты.[^2][^1]
Для вашего TDD Guard и skill это даёт три очевидных усиления:

- **Внешний test runner после каждой RED/GREEN/REFACTOR**
Main orchestrator *сам* запускает `Test command` из Phase Packet и сравнивает фактический статус/вывод с заявленным в пакете (строгой проверкой по exit‑коду и наличию имени теста в выводе). Это напрямую бьёт по сценарию: агент «галлюцинирует» `Status: passed`, хотя тест реально не проходил.[^1]
- **Детализация защиты тестов**
Помимо текущего запрета на Write/Edit в `tests/**`, имеет смысл:
    - Запретить в GREEN/REFACTOR любые правки, которые *семантически* выключают тесты: добавление `.skip`, `xdescribe`, `xit`, `test.only` или оборачивание тестов в `if (false)` (можно ловить в `prevent-test-edit.ts` по простому AST/regex).[^2]
    - Добавить в RED Self‑Checklist пункт: «нет `.skip`/`only` в новых тестах, тест действительно исполняется» и принудительно вызывать `npm test -- <test_file> --runTestsByPath` в Skill’е, а не полагаться только на агента.
- **Ужесточение jest.config‑страховки**
В дополнение к режиму `'ask'` для jest‑конфигов, разумно иметь «теневой» снапшот базового jest‑конфига и проверять дифф: любые изменения, уменьшающие набор запускаемых тестов (игра с `testMatch`, `testPathIgnorePatterns`, `roots`) в не‑RED фазах должны трактоваться как блокирующие (`deny`) с явной эскалацией к пользователю.[^2]

***

## Обязательные verification checkpoints между фазами

Статьи про harness’ы и quality gates подчёркивают, что агенты должны проходить через явные, немягкие чек‑поинты, похожие на командные quality gates: «план → TDD → build fix → review».[^4][^2]
Ваши Self‑Verification Checklists уже задают внутреннюю дисциплину субагентов; поверх этого стоит добавить *внешний* слой проверок в оркестраторе:

- Для **RED**:
    - Тест действительно существует и запускается из `Test command` (орchestrator самостоятельно запускает команду, ожидая *ненулевой* exit‑код и конкретный assertion в выводе).
    - Phase Packet должен содержать `Failure Excerpt` с именем теста/describe + ожидаемым/фактическим значением.
- Для **GREEN**:
    - Тест (и все смежные) запускаются с нулевым exit‑кодом.
    - Ни один файл в `tests/**` и jest‑конфиги не входят в `Changed files`.
    - Diff inventory не содержит явных «дыр» (например, замена тела функции на `return true` при сложном тесте).
- Для **REFACTOR**:
    - Орchestrator делает двойной ран: `before diff` (с текущего коммита) уже зелёный, `after diff` — тоже зелёный.[^5]
    - Phase Packet обязан перечислить `Preserved Invariants` в виде конкретных утверждений (не общих фраз).

Эти внешние чекпоинты можно реализовать как обёртку вокруг уже существующего Bash‑tool, не трогая подсистему агентов.

***

## Формализация test intent и specification‑as‑code

Кейс‑стади по TDD с агентами подчёркивают: AI‑агент работает существенно лучше, когда тесты фактически являются спецификацией поведения, а не просто набором ассертов; помогают Given/When/Then‑формы, property‑based‑тесты и data builders.[^6][^5]
Оптимизация для вашего harness’а:

- **Поле `TestIntent` в Phase Packet RED**
Разрешить/обязать tdd‑test-writer формировать для каждого нового теста компактный intent‑блок:
    - natural language summary;
    - structured `Given / When / Then`;
    - список граничных случаев, которые покрывает данный файл.[^5]
- **Сохранение intent как артефакта**
Хранить intent либо рядом с тестом (`// INTENT: ...` блок), либо в отдельном `tests/INTENT.md` / module‑CLAUDE.md, но с явным ID теста/describe.[^7]
Implementer и последующие агенты должны ссылаться именно на intent, а не пытаться переинтерпретировать требования «по памяти».
- **Property‑based и «контрактные» тесты там, где важна инвариантность**
Для сложной логики (расчёты, лимитирование, парсинг) полезно продвигать шаблоны property‑tests «никогда не происходит X», «значение не выходит за диапазон» и т.д., как в примере rate‑limiter’а с hypothesis.[^5]
Такие тесты сильно уменьшают пространство «угадать требования» и усложняют обход через минимальную фиксацию только happy‑path.

***

## Anti‑patterns в multi‑agent TDD и защита от них

Репозитории и статьи про multi‑agent системы фиксируют типичные анти‑паттерны: чрезмерный параллелизм без координации, перепоручение ответственности вместо явных контрактов, спек‑дрифт (перезапись требований моделью), а также попытки «чинить» архитектурные проблемы в обход основного цикла.[^8][^9][^10]
В вашем контексте особенно опасны:

- **Spec drift через переписывание тестов вместо кода**
Уже частично закрыто Guard’ом; стоит дополнительно фиксировать diff по тестам в отдельный артефакт и требовать от tdd-architect-reviewer явной валидации любых правок, затрагивающих ожидаемое поведение (`expected/actual`).[^2]
- **Тихая деактивация проверок**
Склейка из: изменение тест‑команд (запуск только подмножества тестов), скрытый `.skip`, изменения в CI‑скриптах. Это обсуждается и в командных TDD практиках («не давать инструментам выборочно пропускать тесты»).[^2]
- **«Прыжки» между фазами и делегирование не по контракту**
Anti‑pattern: агент в GREEN пишет «это скорее архитектурная проблема, пусть архитектор решит», вместо строго типизированного FixRequest. Разделение ролей и запрет на субагент‑делегацию (у вас уже есть) соответствуют рекомендациям по построению субагентов и orchestration’а.[^11][^12]

Добавьте в Checklists и skill.md короткий раздел «Known anti‑patterns», чтобы агенты явно обходили эти стратегии и не предлагали их, даже как «оптимизацию».

***

## Артефакты по фазам и long‑running сессии

Исследование long‑running harness’ов показывает, что критически важны два класса артефактов: устойчивый прогресс‑лог (что было сделано, почему, какие тесты покрывают изменения) и структурированный список фич/подзадач с флагами pass/fail.[^3][^1]
Ваши Phase Packets + Task Master уже создают неплохое основание; для long‑running сессий в Claude Code CLI и Cursor можно усилить:

- **Единый «progress ledger»**
Агрегировать Phase Packets в отдельный файл вроде `claude-progress-tdd.json` или в Task Master (как отдельный тип записи), где по каждому subtask фиксируются: список фаз, команды тестов, статусы, FixRequest’ы и ключевые решения.[^1]
- **Стабильный список фич/подзадач с флагами**
Аналог Anthropic feature‑list: Task Master уже ведёт parent task → subtasks; можно обогатить subtasks полями `tests_written`, `tests_passing`, `has_arch_review`, `doc_status` и использовать их как дополнительный guard против преждевременного «DONE».[^3][^1]
- **Clean end‑of‑session state**
Следуя рекомендациям для long‑running агентов, стоит закрепить инвариант: каждая DOCUMENTATION‑фаза оставляет проект в состоянии «готово к merge» — зелёные тесты, нет временных файлов, все изменения описаны в Task Master.[^1][^3]

***

## FixRequest routing: дизайн и метрики

Работы по evals и quality gates для агентов подчёркивают, что качество системы определяется не только одним ответом модели, но и тем, *как хорошо она проходит цикл исправлений*, и насколько эффективно работают маршруты эскалации.[^13][^4]
Для вашего FixRequest‑паттерна это даёт две оси:

- **Уточнение контракта `routeTo`**
Вдохновляясь репозиториями с богатым набором специализированных агентов, можно явнее разделить критерии: всё, что меняет внешнее поведение / типы / безопасность — `implementer`; всё, что сохраняет поведение (структура, дублирование, стилистика) — `refactorer`.[^9][^14]
Это уже декларируется, но имеет смысл продублировать в формах Checklists и валидации ревьюеров (например, отдельный вопрос: «Изменит ли предлагаемый фикс внешнее поведение? Если да — routeTo=implementer»).
- **Метрики маршрутизации**
На уровне harness’а можно логировать для каждого FixRequest:
    - кто создал (code/architect reviewer), `routeTo`, `severity`, количество циклов до закрытия, факт повторной эскалации;
    - перерутинг (случаи, когда refactorer создаёт новый FixRequest, фактически требующий изменения поведения — признак неверного `routeTo`).[^13]
Из этого можно считать: процент FixRequest’ов, закрытых за 1 цикл; долю misrouted FixRequest (когда после 1–2 попыток фикс всё равно передают другому агенту); среднее число циклов на severity. Эти метрики позволяют адаптивно подкручивать лимиты циклов и правила `routeTo`.

***

## Лимит циклов fix‑routing и адаптивные стратегии

Опыт с eval‑ориентированными агентами показывает, что фиксированный лимит попыток (например, 3) — разумный старт, но эффективнее работает адаптивная политика с эскалацией по серьёзности и «степени зацикливания».[^13][^2]
Практический вариант для вашего harness’а:

- **Базовый лимит 3** оставить, но:
    - Для `critical` FixRequest разрешать немедленную эскалацию к пользователю после 2 неудачных циклов.
    - Для `minor` — наоборот, разрешать чуть больше попыток (например, до 4), если изменения явно не рискованные (refactor‑only).
- **Отдельный статус «stalled»**
Если один и тот же FixRequest (по файлу/локации) трижды возвращается с `needs-fix`, архитектурный ревьюер может создавать агрегированный «meta‑FixRequest» с описанием паттерна проблемы, а оркестратор — предлагать пользователю либо упростить требования, либо сузить scope.

***

## Failure propagation и Phase Packet дизайн

Материалы по long‑running harness’ам подчёркивают важность остановки «каскада» после первой ошибки: если проект оставлен в сломанном состоянии, следующий агент должен *сначала* восстановить стабильность, а не продолжать строить поверх руин.[^3][^1]
Для вашего 6‑фазного цикла это означает:

- **Строгую политику «fix before new work»**
Если любой Phase Packet с `Status=failed|needs-fix` уже существует для текущего subtask, новые subtasks не создаются, а TDD‑цикл перезапускается в режиме «fix‑only» до возвращения к зелёному состоянию.[^3]
- **Явное поле `UpstreamPhaseStatus`**
Добавить в пакеты поздних фаз (CODE REVIEW, ARCHITECTURE, DOCUMENTATION) ссылки на статусы ранних фаз (RED/GREEN/REFACTOR) для того же subtask, чтобы ревьюеры могли проверять, не была ли нарушена последовательность (например, refactor без корректно зафиксированной GREEN‑фазы).
- **Диагностическая информация в Phase Packets**
Исследования рекомендуют сохранять «evidence traces» — выдержки логов, важные диффы и т.п., чтобы отладка регрессий не требовала повторного глубокого чтения всего репозитория агентом.[^13][^1]
Ваши `Failure Excerpt` и `Changed files` уже движутся в этом направлении; можно добавить туда, например, краткую сводку тестов, выполненных в фазе (названия тест‑файлов, число упавших/пройденных кейсов).

***

## Защита от «галлюцинаций» в Phase Packets

Во всех серьёзных описаниях harness’ов подчёркивается: нельзя доверять декларативным статусам модели без перепроверки; eval‑агенты и внешние раннеры должны подтверждать утверждения модели о прохождении тестов или завершённости фич.[^1][^13][^3]
В вашем случае:

- **Двойное вычисление статуса**
    - Агенты продолжают формировать Phase Packets со своим `Status`.
    - Орchestrator после этого запускает `Test command` и сравнивает фактический результат с заявленным, записывая в Phase Packet второе поле, вроде `VerifiedTestStatus`.
Любое расхождение автоматически помечает пакет как подозрительный и требует повторного прогона или вмешательства пользователя.
- **Evals‑style spot‑checks**
Можно добавить дополнительного «eval‑субагента» (sonnet/haiku), который эпизодически выбирает подмножество изменений и переоценивает их по логам, диффам и Phase Packets, не полагаясь на основной поток.[^13]
Это особенно полезно для выявления систематических сбоев (например, когда implementer регулярно забывает запускать полный набор тестов).
- **Метрики «ложно зелёных» фаз**
Используя ре‑запуск тестов в harness’е, можно считать долю случаев, когда агент заявил `passed`, а тесты на деле упали. Эта метрика — отличный сигнал для перенастройки промптов и чек‑листов.

***

## Claude Code CLI vs Cursor: интеграция и практические шаги

Публикации и репозитории подчёркивают, что в IDE‑подходе (Cursor/VS Code) часть дисциплины всё равно ложится на разработчика: IDE‑агент не всегда следует тем же hooks/skills, что CLI harness.[^6][^7]
Для согласованности поведения:

- **Синхронизация правил в Cursor**
В `cursor.rules` полезно явно прописать:
    - «Не изменять тесты вне TDD‑RED контекста, если только пользователь не запросил это явно»;
    - «Сначала писать тест (или воспроизводящий регресс тест) для любых новых фич/багфиксов»;
    - Референсы на `CLAUDE.md` и TDD‑skill как источник правды.[^6]
- **Использование того же Task Master/TDD skill как «контрольной» дорожки**
Для сложных задач запускать полный TDD‑skill через Claude Code CLI, а Cursor использовать больше как интерактивный редактор и быстрый контекст‑ассистент, не нарушающий guard’ы.
- **Малые коммиты и clean‑state**
Рекомендации по long‑running агентах и опыт команд с TDD‑агентами подчёркивают пользу маленьких, атомарных коммитов и строгого `clean state` после каждой фазы/сессии: все тесты зелёные, нет незадокументированных изменений.[^15][^3][^1]
Это особенно важно для сценариев, когда одна и та же кодовая база поочерёдно обрабатывается в CLI‑harness’е и через IDE‑агента.

***

Если нужно, можно дальше спуститься до уровня конкретных изменений в `.claude/skills/tdd-integration/skill.md` и `prevent-test-edit.ts` (новые поля Phase Packet, проверка `.skip`/`only`, формат `TestIntent`, логирование FixRequest‑метрик), но уже сейчас ваша архитектура очень хорошо выровнена с современными рекомендациями по long‑running coding‑агентам и TDD‑ориентированным workflow’ам.[^6][^5][^1]
<span style="display:none">[^16][^17][^18][^19][^20][^21][^22][^23][^24][^25][^26][^27][^28]</span>

<div align="center">⁂</div>

[^1]: https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents

[^2]: https://claudecn.com/en/docs/claude-code/workflows/quality-gates/

[^3]: https://www.youtube.com/watch?v=s0Mx6gsWcTM

[^4]: https://www.anthropic.com/engineering/building-effective-agents

[^5]: https://notes.muthu.co/2025/08/tdd-with-coding-agents-to-build-a-rate-limiting-service/

[^6]: https://dev.to/alonoparag/building-with-ai-coding-agents-in-tandem-with-tdd-a-case-study-25ji

[^7]: https://notes.muthu.co/2025/08/tdd-with-coding-agents-building-a-rate-limiting-service/

[^8]: https://github.com/yzyydev/claude_code_sub_agents

[^9]: https://github.com/wshobson/agents

[^10]: https://communities.sas.com/t5/SAS-Communities-Library/Vibe-Coding-with-Generative-AI-and-Test-Driven-Development/ta-p/968477

[^11]: https://github.com/webdevtodayjason/sub-agents

[^12]: https://www.anthropic.com/engineering/building-agents-with-the-claude-agent-sdk

[^13]: https://www.anthropic.com/engineering/demystifying-evals-for-ai-agents

[^14]: https://mcpmarket.com/tools/skills/frontend-tdd-implementation

[^15]: https://www.reddit.com/r/ClaudeAI/comments/1n67d3f/my_claude_code_workflow_tdd_with_small_commits/

[^16]: https://github.com/ruvnet/claude-flow/wiki/CLAUDE-MD-TDD

[^17]: https://github.com/rahulvrane/awesome-claude-agents

[^18]: https://www.anthropic.com/engineering

[^19]: https://github.com/avivl/claude-007-agents

[^20]: https://github.com/vijaythecoder/awesome-claude-agents

[^21]: https://www.anthropic.com/engineering/building-c-compiler

[^22]: https://huggingface.co/blog/Sri-Vigneshwar-DJ/building-effective-agents-with-anthropics-best-pra

[^23]: https://resources.anthropic.com/building-effective-ai-agents

[^24]: https://www.youtube.com/watch?v=ImyEosOoVQ0

[^25]: https://www.linkedin.com/posts/paul-hammond-bb5b78251_claude-tdd-typescript-activity-7390451857384501248-9eKk

[^26]: https://www.linkedin.com/posts/prithvi72_effective-harnesses-for-long-running-agents-activity-7399569533772144640-ZULs

[^27]: https://www.linkedin.com/posts/anthropicresearch_effective-harnesses-for-long-running-agents-activity-7399550329031180288-xR_w

[^28]: https://www.linkedin.com/posts/dave-farley-a67927_andrea-laforgia-has-found-that-tdd-is-the-activity-7366031408709943296-SPe-
